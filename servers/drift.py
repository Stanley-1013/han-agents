"""
SSOT-Code Drift Detection Server

åµæ¸¬ SSOTï¼ˆæ„åœ–å±¤ï¼‰èˆ‡ Code Graphï¼ˆç¾å¯¦å±¤ï¼‰ä¹‹é–“çš„åå·®ã€‚

åå·®é¡å‹ï¼š
1. missing_implementation - SSOT å®šç¾©äº†ä½† Code æ²’å¯¦ä½œ
2. missing_spec - Code å­˜åœ¨ä½† SSOT æ²’æ–‡æª”åŒ–
3. mismatch - å…©è€…éƒ½æœ‰ä½†å…§å®¹ä¸ä¸€è‡´
4. stale_spec - SSOT æ–‡æª”éæ™‚

è¨­è¨ˆåŸå‰‡ï¼š
- åµæ¸¬åå·®ï¼Œä½†ä¸è‡ªå‹•ä¿®æ­£
- åå·®éœ€è¦äººé¡æ±ºç­–
- æä¾›å¯è¡Œå‹•çš„å»ºè­°
"""

import os
import re
from typing import List, Dict, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta

# =============================================================================
# SCHEMAï¼ˆä¾› Agent åƒè€ƒï¼‰
# =============================================================================

SCHEMA = """
=== Drift Detection API ===

detect_all_drifts(project, project_dir=None) -> DriftReport
    åµæ¸¬å°ˆæ¡ˆæ‰€æœ‰ SSOT-Code åå·®
    Args:
        project: å°ˆæ¡ˆåç¨±ï¼ˆç”¨æ–¼ Code Graph æŸ¥è©¢ï¼‰
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆç”¨æ–¼è®€å–å°ˆæ¡ˆç´š SSOT .claude/pfc/INDEX.mdï¼‰
    Returns: {
        'has_drift': bool,
        'drift_count': int,
        'drifts': [DriftItem],
        'summary': str,
        'checked_at': datetime
    }

detect_flow_drift(project, flow_id) -> DriftReport
    åµæ¸¬ç‰¹å®š Flow çš„åå·®
    Returns: åŒä¸Š

detect_coverage_gaps(project) -> List[CoverageGap]
    åµæ¸¬æ¸¬è©¦è¦†è“‹ç¼ºå£
    Returns: [{
        'node_id': str,
        'node_kind': str,
        'name': str,
        'file_path': str,
        'has_test': bool
    }]

get_drift_summary(project) -> str
    å–å¾—åå·®æ‘˜è¦ï¼ˆMarkdown æ ¼å¼ï¼‰

resolve_drift(project, drift_id, resolution) -> bool
    æ¨™è¨˜åå·®å·²è§£æ±º
    - resolution: 'fixed_code' | 'updated_spec' | 'intentional' | 'wont_fix'
"""

# =============================================================================
# Data Models
# =============================================================================

@dataclass
class DriftItem:
    """å–®ä¸€åå·®é …ç›®"""
    id: str                              # å”¯ä¸€è­˜åˆ¥ç¬¦
    type: str                            # missing_implementation, missing_spec, mismatch, stale_spec
    severity: str                        # critical, high, medium, low
    ssot_item: Optional[str] = None      # SSOT å´çš„é …ç›®
    code_item: Optional[str] = None      # Code å´çš„é …ç›®
    description: str = ""
    suggestion: str = ""                 # å»ºè­°çš„ä¿®å¾©æ–¹å¼
    detected_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict:
        return {
            'id': self.id,
            'type': self.type,
            'severity': self.severity,
            'ssot_item': self.ssot_item,
            'code_item': self.code_item,
            'description': self.description,
            'suggestion': self.suggestion,
            'detected_at': self.detected_at.isoformat() if self.detected_at else None
        }


@dataclass
class DriftReport:
    """åå·®å ±å‘Š"""
    has_drift: bool = False
    drift_count: int = 0
    drifts: List[DriftItem] = field(default_factory=list)
    summary: str = ""
    checked_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict:
        return {
            'has_drift': self.has_drift,
            'drift_count': self.drift_count,
            'drifts': [d.to_dict() for d in self.drifts],
            'summary': self.summary,
            'checked_at': self.checked_at.isoformat()
        }


# =============================================================================
# Detection Logic
# =============================================================================

def detect_all_drifts(project: str, project_dir: str = None) -> DriftReport:
    """
    åµæ¸¬å°ˆæ¡ˆæ‰€æœ‰ SSOT-Code åå·®

    Args:
        project: å°ˆæ¡ˆåç¨±ï¼ˆç”¨æ–¼ Code Graph æŸ¥è©¢ï¼‰
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆç”¨æ–¼è®€å–å°ˆæ¡ˆç´š SSOT INDEXï¼‰
                     å¦‚æœä¸å‚³ï¼Œåªæœƒæª¢æŸ¥å…¨å±€ SSOT

    æª¢æŸ¥é …ç›®ï¼š
    1. SSOT å®šç¾©çš„ Flow æ˜¯å¦æœ‰å°æ‡‰å¯¦ä½œ
    2. Code ä¸­çš„ä¸»è¦æ¨¡çµ„æ˜¯å¦æœ‰ SSOT æ–‡æª”
    3. SSOT å’Œ Code çš„çµæ§‹æ˜¯å¦ä¸€è‡´
    """
    from servers.ssot import parse_index
    from servers.code_graph import get_code_nodes, get_code_graph_stats

    drifts = []
    drift_id = 0

    def make_drift_id():
        nonlocal drift_id
        drift_id += 1
        return f"drift-{project}-{drift_id:04d}"

    # 1. å–å¾— SSOT å®šç¾©ï¼ˆå„ªå…ˆä½¿ç”¨å°ˆæ¡ˆç´š INDEXï¼‰
    try:
        ssot_data = parse_index(project_dir)
        # parse_index è¿”å› {'flows': [...], 'domains': [...], ...}
        # å±•å¹³ç‚ºç¯€é»åˆ—è¡¨
        ssot_nodes = []
        for kind, nodes in ssot_data.items():
            for node in nodes:
                if isinstance(node, dict):
                    node['kind'] = kind.rstrip('s')  # flows -> flow
                    ssot_nodes.append(node)
    except Exception as e:
        return DriftReport(
            has_drift=False,
            summary=f"Cannot detect drift: SSOT Index not found ({str(e)})"
        )

    # 2. å–å¾— Code Graph
    code_nodes = get_code_nodes(project, limit=1000)
    code_stats = get_code_graph_stats(project)

    if code_stats['node_count'] == 0:
        return DriftReport(
            has_drift=False,
            summary="Cannot detect drift: Code Graph is empty. Run sync first."
        )

    # å»ºç«‹ç´¢å¼•
    ssot_by_id = {n.get('id'): n for n in ssot_nodes}
    ssot_flows = [n for n in ssot_nodes if n.get('kind') == 'flow']
    ssot_domains = [n for n in ssot_nodes if n.get('kind') == 'domain']

    code_files = [n for n in code_nodes if n['kind'] == 'file']
    code_file_paths = set(n['file_path'] for n in code_files)

    # 3. æª¢æŸ¥ Flow â†’ å¯¦ä½œ
    for flow in ssot_flows:
        flow_id = flow.get('id', '')
        flow_name = flow_id.replace('flow.', '').lower()
        ref = flow.get('ref', '')

        # æ­£è¦åŒ–åç¨±ï¼ˆè™•ç† - å’Œ _ çš„å·®ç•°ï¼‰
        flow_name_normalized = flow_name.replace('-', '_').replace('.', '_')
        flow_name_parts = set(flow_name.replace('-', ' ').replace('_', ' ').split())

        # å¦‚æœæœ‰ refï¼Œå„ªå…ˆæª¢æŸ¥ ref æŒ‡å‘çš„æª”æ¡ˆ
        has_impl = False
        matched_files = []

        if ref:
            # ref ç›´æ¥æŒ‡å®šæª”æ¡ˆï¼Œæª¢æŸ¥æ˜¯å¦å­˜åœ¨æ–¼ Code Graph
            for file_path in code_file_paths:
                if ref in file_path or file_path.endswith(ref):
                    has_impl = True
                    matched_files.append(file_path)
                    break

        # å¦‚æœæ²’æœ‰ ref æˆ– ref æ²’åŒ¹é…åˆ°ï¼Œç”¨å•Ÿç™¼å¼åŒ¹é…
        if not has_impl:
            for file_path in code_file_paths:
                file_name = os.path.basename(file_path).lower()
                file_stem = os.path.splitext(file_name)[0]
                file_stem_normalized = file_stem.replace('-', '_').replace('.', '_')

                # æ­£è¦åŒ–å¾ŒåŒ¹é…
                if flow_name_normalized in file_stem_normalized or file_stem_normalized in flow_name_normalized:
                    has_impl = True
                    matched_files.append(file_path)
                # éƒ¨åˆ†åç¨±åŒ¹é…ï¼ˆè‡³å°‘ 2 å€‹è©ç›¸ç¬¦ï¼‰
                elif len(flow_name_parts) >= 2:
                    file_parts = set(file_stem.replace('-', ' ').replace('_', ' ').split())
                    common = flow_name_parts & file_parts
                    if len(common) >= min(2, len(flow_name_parts)):
                        has_impl = True
                        matched_files.append(file_path)
                # è·¯å¾‘åŒ…å«
                elif flow_name_normalized in file_path.lower().replace('-', '_'):
                    has_impl = True
                    matched_files.append(file_path)

        if not has_impl:
            drifts.append(DriftItem(
                id=make_drift_id(),
                type='missing_implementation',
                severity='high',
                ssot_item=flow_id,
                description=f"Flow '{flow_id}' defined in SSOT but no matching code files found",
                suggestion=f"Create implementation file for {flow_id} or update SSOT if flow was removed"
            ))

    # 4. æª¢æŸ¥ Code â†’ SSOT æ–‡æª”
    # æ‰¾å‡ºé‡è¦çš„ Code æ¨¡çµ„ï¼ˆapi/, routes/, controllers/, services/ï¼‰
    important_patterns = ['api/', 'routes/', 'controllers/', 'services/', 'handlers/']

    for code_file in code_files:
        file_path = code_file.get('file_path', '')

        # æª¢æŸ¥æ˜¯å¦æ˜¯é‡è¦æ¨¡çµ„
        is_important = any(p in file_path for p in important_patterns)
        if not is_important:
            continue

        # æå–å¯èƒ½çš„ flow åç¨±
        file_name = os.path.splitext(os.path.basename(file_path))[0]
        expected_flow_id = f"flow.{file_name}"

        # æª¢æŸ¥ SSOT æ˜¯å¦æœ‰å°æ‡‰æ–‡æª”
        has_spec = expected_flow_id in ssot_by_id

        # ä¹Ÿæª¢æŸ¥æ¨¡ç³ŠåŒ¹é…
        if not has_spec:
            for ssot_id in ssot_by_id:
                if file_name.lower() in ssot_id.lower():
                    has_spec = True
                    break

        if not has_spec:
            drifts.append(DriftItem(
                id=make_drift_id(),
                type='missing_spec',
                severity='medium',
                code_item=file_path,
                description=f"Code file '{file_path}' exists but no SSOT spec found",
                suggestion=f"Create SSOT spec for '{expected_flow_id}' in brain/ssot/flows/"
            ))

    # 5. å»ºç«‹å ±å‘Š
    summary_parts = []
    if drifts:
        by_type = {}
        for d in drifts:
            by_type[d.type] = by_type.get(d.type, 0) + 1

        for t, count in sorted(by_type.items()):
            summary_parts.append(f"{count} {t}")

        summary = f"Found {len(drifts)} drift(s): " + ", ".join(summary_parts)
    else:
        summary = "No drift detected. SSOT and Code are in sync."

    return DriftReport(
        has_drift=len(drifts) > 0,
        drift_count=len(drifts),
        drifts=drifts,
        summary=summary
    )


def detect_flow_drift(project: str, flow_id: str) -> DriftReport:
    """åµæ¸¬ç‰¹å®š Flow çš„åå·®"""
    from servers.ssot import load_flow_spec
    from servers.graph import get_neighbors
    from servers.code_graph import get_code_nodes

    drifts = []
    drift_id = 0

    def make_drift_id():
        nonlocal drift_id
        drift_id += 1
        return f"drift-{project}-{flow_id}-{drift_id:04d}"

    # 1. å–å¾— Flow Spec
    flow_spec = None
    try:
        flow_spec = load_flow_spec(flow_id)
    except:
        pass

    if not flow_spec:
        return DriftReport(
            has_drift=True,
            drift_count=1,
            drifts=[DriftItem(
                id=make_drift_id(),
                type='missing_spec',
                severity='high',
                ssot_item=flow_id,
                description=f"Flow spec for '{flow_id}' not found",
                suggestion=f"Create brain/ssot/flows/{flow_id.replace('flow.', '')}.md"
            )],
            summary=f"Flow '{flow_id}' has no SSOT specification"
        )

    # 2. å–å¾— Graph é„°å±…ï¼ˆSSOT å±¤ï¼‰
    try:
        neighbors = get_neighbors(flow_id, project, depth=1)
    except:
        neighbors = []

    # 3. å–å¾—ç›¸é—œ Code
    flow_name = flow_id.replace('flow.', '').lower()
    code_nodes = get_code_nodes(project, limit=500)

    related_code = []
    for node in code_nodes:
        if flow_name in node.get('file_path', '').lower():
            related_code.append(node)
        elif flow_name in node.get('name', '').lower():
            related_code.append(node)

    # 4. æª¢æŸ¥ä¸€è‡´æ€§
    # å¾ Spec ä¸­æå–é æœŸçš„ API endpoints
    api_pattern = re.compile(r'(?:GET|POST|PUT|DELETE|PATCH)\s+(/[^\s]+)', re.IGNORECASE)
    expected_apis = set(api_pattern.findall(flow_spec))

    # æª¢æŸ¥æ˜¯å¦æœ‰å°æ‡‰çš„ Code
    if not related_code and expected_apis:
        drifts.append(DriftItem(
            id=make_drift_id(),
            type='missing_implementation',
            severity='high',
            ssot_item=flow_id,
            description=f"Flow '{flow_id}' specifies APIs but no related code found",
            suggestion="Implement the APIs defined in the flow spec"
        ))

    # 5. æª¢æŸ¥æ¸¬è©¦è¦†è“‹
    has_test = any('test' in n.get('file_path', '').lower() for n in related_code)
    test_neighbors = [n for n in neighbors if n.get('kind') == 'test']

    if not has_test and not test_neighbors:
        drifts.append(DriftItem(
            id=make_drift_id(),
            type='missing_implementation',
            severity='medium',
            ssot_item=flow_id,
            description=f"Flow '{flow_id}' has no test coverage",
            suggestion=f"Create test file for {flow_id}"
        ))

    # 6. å»ºç«‹å ±å‘Š
    if drifts:
        summary = f"Flow '{flow_id}' has {len(drifts)} drift(s)"
    else:
        summary = f"Flow '{flow_id}' is in sync with code"

    return DriftReport(
        has_drift=len(drifts) > 0,
        drift_count=len(drifts),
        drifts=drifts,
        summary=summary
    )


def detect_coverage_gaps(project: str) -> List[Dict]:
    """
    åµæ¸¬æ¸¬è©¦è¦†è“‹ç¼ºå£

    æ‰¾å‡ºæ²’æœ‰å°æ‡‰æ¸¬è©¦çš„é‡è¦ç¨‹å¼ç¢¼ã€‚
    """
    from servers.code_graph import get_code_nodes, get_code_edges

    # å–å¾—æ‰€æœ‰ nodes
    nodes = get_code_nodes(project, limit=1000)
    edges = get_code_edges(project, kind='tests', limit=500)

    # æ‰¾å‡ºè¢«æ¸¬è©¦è¦†è“‹çš„ nodes
    covered_ids = set(e['to_id'] for e in edges)

    # æ‰¾å‡ºé‡è¦ä½†æœªè¦†è“‹çš„ nodes
    gaps = []
    important_kinds = {'function', 'class', 'api'}

    for node in nodes:
        if node['kind'] not in important_kinds:
            continue

        # è·³éæ¸¬è©¦æª”æ¡ˆæœ¬èº«
        if 'test' in node.get('file_path', '').lower():
            continue

        # è·³é private å‡½å¼
        if node.get('visibility') == 'private':
            continue

        # æª¢æŸ¥æ˜¯å¦æœ‰æ¸¬è©¦
        has_test = node['id'] in covered_ids

        # ä¹Ÿç”¨æª”æ¡ˆåç¨±å•Ÿç™¼å¼æª¢æŸ¥
        if not has_test:
            file_path = node.get('file_path', '')
            file_stem = os.path.splitext(os.path.basename(file_path))[0]
            test_patterns = [
                f"{file_stem}.test",
                f"{file_stem}.spec",
                f"test_{file_stem}",
            ]
            for test_node in nodes:
                if test_node['kind'] == 'file' and 'test' in test_node.get('file_path', '').lower():
                    test_file = os.path.basename(test_node.get('file_path', '')).lower()
                    if any(p.lower() in test_file for p in test_patterns):
                        has_test = True
                        break

        if not has_test:
            gaps.append({
                'node_id': node['id'],
                'node_kind': node['kind'],
                'name': node['name'],
                'file_path': node.get('file_path'),
                'line_start': node.get('line_start'),
                'has_test': False
            })

    return gaps


# =============================================================================
# Reporting
# =============================================================================

def get_drift_summary(project: str, project_dir: str = None) -> str:
    """å–å¾—åå·®æ‘˜è¦ï¼ˆMarkdown æ ¼å¼ï¼‰

    Args:
        project: å°ˆæ¡ˆåç¨±
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆç”¨æ–¼è®€å–å°ˆæ¡ˆç´š SSOTï¼‰
    """
    report = detect_all_drifts(project, project_dir)

    lines = [
        "# SSOT-Code Drift Report",
        "",
        f"**Project**: {project}",
        f"**Checked at**: {report.checked_at.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**Status**: {'âš ï¸ Drift detected' if report.has_drift else 'âœ… In sync'}",
        "",
    ]

    if not report.has_drift:
        lines.append("No drift detected. SSOT and Code are in sync.")
        return "\n".join(lines)

    lines.append(f"## Summary")
    lines.append("")
    lines.append(report.summary)
    lines.append("")

    # æŒ‰åš´é‡ç¨‹åº¦åˆ†çµ„
    by_severity = {'critical': [], 'high': [], 'medium': [], 'low': []}
    for drift in report.drifts:
        by_severity.get(drift.severity, by_severity['medium']).append(drift)

    severity_icons = {
        'critical': 'ğŸ”´',
        'high': 'ğŸŸ ',
        'medium': 'ğŸŸ¡',
        'low': 'ğŸŸ¢'
    }

    for severity in ['critical', 'high', 'medium', 'low']:
        items = by_severity[severity]
        if not items:
            continue

        lines.append(f"## {severity_icons[severity]} {severity.title()} ({len(items)})")
        lines.append("")

        for drift in items:
            lines.append(f"### [{drift.type}] {drift.id}")
            lines.append("")
            lines.append(f"**Description**: {drift.description}")
            if drift.ssot_item:
                lines.append(f"**SSOT**: `{drift.ssot_item}`")
            if drift.code_item:
                lines.append(f"**Code**: `{drift.code_item}`")
            lines.append(f"**Suggestion**: {drift.suggestion}")
            lines.append("")

    return "\n".join(lines)


def get_coverage_summary(project: str) -> str:
    """å–å¾—æ¸¬è©¦è¦†è“‹ç¼ºå£æ‘˜è¦"""
    gaps = detect_coverage_gaps(project)

    lines = [
        "# Test Coverage Gaps",
        "",
        f"**Project**: {project}",
        f"**Gaps found**: {len(gaps)}",
        "",
    ]

    if not gaps:
        lines.append("All important code has test coverage. âœ…")
        return "\n".join(lines)

    lines.append("## Uncovered Code")
    lines.append("")
    lines.append("| Kind | Name | File | Line |")
    lines.append("|------|------|------|------|")

    for gap in gaps[:50]:  # é™åˆ¶é¡¯ç¤ºæ•¸é‡
        lines.append(
            f"| {gap['node_kind']} | `{gap['name']}` | {gap['file_path']} | {gap['line_start']} |"
        )

    if len(gaps) > 50:
        lines.append(f"\n... and {len(gaps) - 50} more")

    return "\n".join(lines)
